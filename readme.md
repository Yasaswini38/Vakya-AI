Markdown

# VÄkya AI ğŸ—£ï¸

VÄkya, which means "sentence" in Sanskrit, is a conversational AI that allows users to interact with a Large Language Model (LLM) using their voice. Speak. Understand. Reply.
Thatâ€™s **VÄkya** , a full loop of human-like conversation, built with **Python**, driven by **FastAPI**, and delivered in a crisp, modern UI.

***

### Features 

* **Voice-to-Voice Interaction**: Talk to the AI and hear it respond back in real time.  
* **Real-time Transcription**: See your speech transcribed instantly on screen.  
* **Conversational Memory**: Maintains context within a session for natural dialogue.  
* **Session Management**: Start new chats or revisit past conversations.  
* **Voice Customization**: Choose from multiple voices for responses.  
* **Fun Skills Built-in**: Weather updates, News headlines, Jokes on demand.  
* **Modern UI**: Cute & aesthetic responsive interface with chat history panel.

***

### Technologies Used 

* **FastAPI** â€” backend framework for REST + WebSocket support  
* **Jinja2** â€” template rendering for frontend  
* **AssemblyAI** â€” speech-to-text (transcription)  
* **Google Gemini** â€” LLM for text generation  
* **Murf.ai** â€” text-to-speech (streaming natural voices)  
* **python-dotenv** â€” for managing API keys securely  
* **HTML, CSS, JavaScript** â€” responsive UI (with chat history, persona selection)

***

### Architecture 

The application follows a simple client-server architecture:

1. Userâ€™s voice recorded via browser microphone  
2. Audio streamed to FastAPI backend over WebSocket  
3. AssemblyAI transcribes speech â†’ text  
4. Transcribed text + history â†’ Gemini (LLM) for response generation  
5. Response text â†’ Murf.ai â†’ natural voice audio stream  
6. Frontend shows transcription, AIâ€™s reply, and plays back the audio  

***

### Getting Started

#### Prerequisites

* Python 3.8+
* `pip`
* API keys for **AssemblyAI**, **Google Gemini**, and **Murf.ai**.

#### Installation and Setup

1.  **Clone the repository**:
    ```sh
    git clone https://github.com/Yasaswini38/Vakya-AI
    cd  Vakya-AI
    ```

2.  **Install dependencies**:
    ```sh
    pip install -r requirements.txt
    ```

3.  **Set up environment variables**:
    Create a `.env` file in the root directory and add your API keys:
    ```sh
    MURF_API_KEY="YOUR_MURF_API_KEY"
    ASSEMBLYAI_API_KEY="YOUR_ASSEMBLYAI_API_KEY"
    GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
    NEWS_API_KEY="YOUR_NEWS_API_KEY"
    ```

4.  **Run the application**:
    ```sh
    uvicorn main:app --reload
    ```
    The server will run on `http://127.0.0.1:8000`.

***

### How to Run the API Server

Once the setup is complete, the `uvicorn main:app --reload` command will start the APP

#### Project Structure
```plaintext
â”œâ”€â”€ main.py              # FastAPI backend
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # Main UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ script.js        # Frontend JS
â”‚   â”œâ”€â”€ style.css        # Styles
â”‚   â””â”€â”€ voices.json      # Voice list
â”œâ”€â”€ uploads/             # Uploaded audio
â”œâ”€â”€ .env                 # API keys
â””â”€â”€ README.md
